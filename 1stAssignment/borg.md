## 概述
> Google的Borg系统是一个集群管理工具，在它上面运行着成千上万的job，这些job来自许许多多不同的应用，并且跨越多个集群，而每个集群又由大量的机器构成。
> Borg通过组合准入控制，高效的任务打包，超额负载以及基于进程级别性能隔离的机器共享从而实现高利用率。它支持那些高可用的应用，它们的运行时特性能够最小化错误恢复时间，它们的调度策略降低了相关错误发生的可能性。为了简化用户的使用，Borg提供了一个声明工作规范语言，名称服务一体化机制，实时job监控以及一系列用于分析和模拟系统行为的工具。

---

## 简介
> 这个叫做Borg的集群管理系统确认，调度，启动，重启以及监视Google运行的所有应用。
#### Borg提供三大优点
- 它隐藏了资源管理以及错误处理，因此用户能集中精力开发应用
- 具有非常高的可靠性和可用性，从而能够支持具有这些特性的应用
- 能够让我们跨越数以千计的机器有效地运行负载。

**Borg并不是第一个解决这些问题的系统，但是它是少数能在这么大规模处理这些问题并且还能达到这样弹性和完整性的系统之一。**

---

## 用户视角
> Borg的主要用户是Google的开发者以及运行Google应用和服务的系统管理员（网站可靠性工程师或者简称SRE）。用户以job的形式向Borg提交工作，每个job由运行一个或多个运行相同程序的task组成。每个job运行在一个Borg cell中，并且将一组机器当做一个单元进行管理。

### 工作负载
> Borg运行各种各样的负载，这些负载主要可以分为两类。第一类是长时间运行不能停止的服务并且要求能够处理短暂的，延迟敏感的请求（延迟要求在几微秒到几百毫秒之间）。这些服务主要用于面向终端用户的服务，例如Gmail，Google Docs，web搜索以及内部的一些基础设施服务（例如BigTable）。第二类是通常需要几秒到几天来完成的批处理job，这些job对短时间的性能波动并不是非常敏感。这些负载通常在cell之间混合分布，每个cell随着主要租户以及时间的不同会运行各种不同的应用：批处理类型的job来了又走而许多面向终端用户的job又期望一个能长时间使用的模式。Borg要求能很好地处理所有的情况。

### 集群与cell
> 一个cell中的机器通常属于单个集群，并且由数据中心规模的高性能网络结构连接起来。一个集群通常存在于单个数据中心里，而多个数据中心的集合构成了一个site。一个集群通常包含一个大的cell，也许其中还有一些小规模用于测试或者其他特殊目的的cell。

### job与task
> Borg的一个job的属性通常包括它的名字，所有者以及它拥有的task的名字。job可以存在一定的约束，从而让它的task运行在有特定属性的机器上，例如特定的处理器架构，操作系统版本，以及外部IP。约束可以分为硬性的或软性的。软性的约束更像是一种优先建议而不是要求。一个job的运行可以推迟到上一个结束之后才开始并且一个job只能运行在一个cell中。

> 每个task代表了运行在一个容器或者一个物理机器内的一系列Linux进程。每个task同样拥有各自的属性，例如资源需求以及task在job里的索引。大多数task属性在同一个job里都是相同的，但是提供了针对具体task的命令行标志之后也能对它们进行重载。Borg程序通常都是静态链接的从而能减少对它们运行环境的依赖，并且二进制文件和数据文件都以包的形式组织起来，而它们的安装都是由Borg策划的。

> 用户通常通过向Borg发送远程过程调用，即利用一些命令行工具，来操作job。大多数的job描述都是用一种声明性的配置语言BCL写成的。BCL是GCL的一个变体，GCL会产生protobuf文件，而BCL会在它之上扩展一些Borg特有的关键词。BCL提供了lambda函数用于计算，应用程序通常利用它来调整对环境的配置。Borg的job配置文件和Aurora的配置文件有很多类似之处。

### allocs
> Borg的alloc（allocation的简写）操作是指在一台机器上预留一些资源，从而能够在其上运行一个或者多个资源；这些资源不管是否被使用都是保持被分配状态的。Allocs操作可以被用来保留资源用于未来task的使用，也可以用于在停止以及启动一个task之间保存资源，还可以用于将不同job里的task收集起来，让它们运行在同一台机器中：比如一个web服务器实例以及相关的用于将本地磁盘的服务器URL记录拷贝到分布式文件系统的task。被alloc操作之后的资源和机器中的其他资源是被同等对待的，运行在同一个alloc操作之上的多个task共享其中的资源。如果一个alloc操作必须被重定向到另一台机器上，那么之上的任务就必须随着alloc操作被重新调度。一个alloc集就像是一个job：它是一系列的alloc操作用于在多台机器上预留资源。一旦一个alloc操作被创建，一个或多个job就能被提交并且运行在它之上。简单起见，我们一般用“task”来代之一次alloc操作或者顶层的task（一个在alloc操作之外的task），而“job”指一个job或者一个alloc操作集。

### 优先级，配额以及准入控制
> 如果出现了超出处理能力的负载怎么办？解决方法是优先级和配额。每个job都有一个优先级（priority），也就是一个小的正整数。一个高优先级的task可以以牺牲另一个较低优先级的task为代价来获取资源，即使这种牺牲包括抢占或者杀死较低优先级的task。Borg对于不同的使用定义了一种非重叠的优先级带，包括（优先级从高到底排列）：监视，生产，批任务以及尽力而为的工作（也可以理解为测试或者免费的工作）。通常一个被抢占的task会被重新调度到cell的其他地方，而抢占操作也有可能产生级联影响：比如一个高优先级的task抢占了一个较低优先级的task，而后者又去抢占更低优先级的task，从而不断级联下去。为了防止这种级联事件的发生，我们并不允许同处于生产优先级带的task相互抢占。细粒度的优先级划分在其他一些情况下还是相当有用的：比如MapReduce的master类型的task的优先级要高于它控制的worker，从而提高整个系统的可靠性。优先级用来表示在一个cell中运行或者等待运行的job的相对重要性。而配额（quota）则表示哪些job能够被调度。配额我们可以理解为在给定优先级下的资源请求向量（CPU，RAM，磁盘等等）。资源请求是指在一段时间内，一般是一个月内，一个用户的job能请求的最大资源数目（比如一个prod请求了20TB的RAM，时间是从现在到七月份，在XX cell中）。配额检查也是准入控制的一部分，而不是调度：一个配额要求未被满足的job是会被立刻拒绝的。高优先级job的配额通常会比低优先级job的配额花费更多。比如生产优先级的配额会被限制在一个cell真实可获取的资源数量范围内。因此，如果一个用户提交了一个生产优先级的job，并且配额合适，那么就能期待它运行。配额的分配是在Borg之外进行的并且和我们的物理容量规划密切相关。它们通常反映了不同数据中心配额的价格和可用性。一个用户的job只有在满足了它所在优先级的配额之后才能被准入。配额的使用减少了对像优势资源公平（Dominant Resource Fairness，DRF）这样的策略的使用。


### 命名以及监控
> 单单创造并且部署task还是远远不够的，因为一个服务的客户端以及其他系统需要能够找到它们，即使在它们被调度到新的机器上以后。因此，Borg为每个task创造了一个叫”Borg name service“(BNS)类型的名字，这个名字中包含了cell的名字，job的名字以及task的编号。Borg会将task的主机名，端口号以及这个BNS名字写入Chubby里面一个一致的，高可用的文件中，而这个文件通常被我们的RPC系统用于查找task。BNS名字同样被用作task的DNS名字基础，同时Borg会在job的大小或者task的健康状况改变时将它们写入Chubby中，之后负载均衡器就能决定将请求路由到什么地方了。几乎Borg之下运行的每一个task都有一个内置的HTTP server用于发布task的健康状况以及其他许多的性能指标（RPC延迟等等）。Borg会监视健康检查的URL并且会重启那些没有即使回复的task或者直接返回一个HTTP 错误代码。其他数据通过另外一些监控工具进行监控，并且对服务对象级别的违规行为进行报警。